import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns


data = pd.read_csv("Churn_Modelling.csv")

data.head()

data.info()


for col in data.columns :
    print(" col_name : "  , col , " unique percentage : " , len(data[col].unique())/len(data))


 data = data.drop(["RowNumber", "CustomerId", "Surname"], axis = 1)
 data.head()


from sklearn.preprocessing import LabelEncoder

d_types = dict(data.dtypes)

for name, type_ in d_types.items():
    if str(type_) == 'object' :
        Le = LabelEncoder()
        data[name] = Le.fit_transform(data[name])
        
data.head()


from sklearn.preprocessing import OneHotEncoder

onehotencoder = OneHotEncoder()
encodings = onehotencoder.fit_transform(data['Geography'].values.reshape(-1, 1)).toarray()

values = data["Geography"].unique()

for val in values:
    data["Geography_" + str(val)] = encodings[:, val]
    
data = data.drop(["Geography"], axis = 1)
    
data.head()


remaining_columns = list(data.columns)
remaining_columns.remove("Exited")


X = data[remaining_columns].values
Y = data['Exited'].values.astype(np.uint8)


from sklearn.model_selection import train_test_split

Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size = 0.2, random_state = 4)


from sklearn.preprocessing import StandardScaler

Scaler = StandardScaler()
Xtrain = Scaler.fit_transform(Xtrain)
Xtest = Scaler.transform(Xtest)


plt.ylim(-1, 1)

means = []
for i in range(X.shape[1]):
    means.append(np.mean(Xtest[:, i]))
    
plt.plot(means, scaley=False)


plt.ylim(0, 2)

vars = []
for i in range(X.shape[1]):
    vars.append(np.var(Xtest[:, 1]))
    
plt.plot(vars)



from sklearn.linear_model import LogisticRegression

model = LogisticRegression()
model.fit(Xtrain, Ytrain)

model.score(Xtest, Ytest)



model.coef_

model.intercept_


def sigmoid(x):
    return 1/(1 + np.exp(-X))

sigmoid(model.coef_.dot(Xtest[10,:]) + model.intercept_)


np.round(sigmoid(model.coef_.dot(Xtest[10,:]) + model.intercept_))



model.predict(Xtest[10,:].reshape(1, -1))


from sklearn.linear_model import LogisticRegression
from sklearn.feature_selection import RFECV

model = LogisticRegression()
rfecv = RFECV(model , step = 1, min_features_to_select = 6 , n_jobs = -1)
rfecv.fit(Xtrain, Ytrain)



rfecv.support_

rfecv.ranking_

selected_features = np.where(rfecv.support_)[0]
Xtrain = Xtrain[:, selected_features]
Xtest = Xtest[:, selected_features]


model.fit(Xtrain, Ytrain)
model.score(Xtest, Ytest)

model.coef_

model.intercept_


from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV
from sklearn.feature_selection import RFECV

model = LogisticRegression()
rfecv = RFECV(model , step = 1, min_features_to_select = 4, n_jobs = -1)
rfecv.fit(Xtrain, Ytrain)



selected_features = np.where(rfecv.support_)[0]
Xtrain = Xtrain[:,selected_features]
Xtest = Xtest[:, selected_features]


param_grid = {'penalty' : ['12'],
             'C' : [1.0, 2.0, 3,0],
             'max_iter' : [100, 200, 300 , 500],
             'solver' : ['newton-cg', 'Ibfgs', 'sag', 'saga']}

model = LogisticRegression()
grid_search = GridSearchCV(model, param_grid)
grid_search.fit(Xtrain, Ytrain)



grid_search.best_params_

grid_search.score(Xtest, Ytest)

from sklearn.preprocessing import StandardScaler

Scaler = StandardScaler()
X = Scaler.fit_transform(X)

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV
from sklearn.feature_selection import RFECV

model = LogisticRegression()
rfecv = RFECV(model , step = 1, min_features_to_select = 4, n_jobs = -1)
rfecv.fit(X, Y)


selected_features = np.where(rfecv.support_)[0]
X = X[:,selected_features]

from sklearn.model_selection import KFold

k_fold = KFold(n_splits=5)

test_scores = []
for train_idx, test_idx in k_fold.split(X):
    Xtrain = X[train_idx]
    Ytrain = Y[train_idx]
    
    Xtest = X[test_idx]
    Ytest = Y[test_idx]
    
    model = LogisticRegression()
    model.fit(Xtrain, Ytrain)
    
    test_scores.append(model.score(Xtest, Ytest))
    

import matplotlib.pyplot as plt

plt.plot(test_scores)
plt.plot([np.mean(test_scores)]*len(test_scores))
plt.show()



print("Cross Validation Score:", np.mean(test_scores))


from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, roc_auc_score, precision_score, recall_score

def precision(label, confusion_matrix):
    col = confusion_matrix[:, label]
    return confusion_matrix[label, label]/col.sum()

def recall(label, confusion_matrix):
    row = confusion_matrix[label, :]
    return confusion_matrix[label, label]/row.sum()

def f1_score(precision, recall):
    return 2 * (precision * recall)/(precision + recall)


from sklearn.linear_model import LogisticRegression 

model = LogisticRegression()
model.fit(Xtrain , Ytrain)

predictions = model.predict(Xtest)


matrix = confusion_matrix(Ytest, predictions)
sns.heatmap(matrix, annot=True)



precision(1, matrix), recall(1, matrix)



print(f'Accuracy Score: {accuracy_score(Ytest, predictions)}')
print(f'Confusion Matrix: \n {confusion_matrix(Ytest, predictions)}')
print(f'Area Under Curve: {roc_auc_score(Ytest, predictions)}')
print(f'Recall Score: {recall_score(Ytest, predictions)}')


value_counts = dict(data["Exited"].value_counts())
print(value_counts)



for key , value in value_counts.items():
    value_counts[key] = value/len(data)

print(value_counts)



class_weights = {}

for key , value in value_counts.items():
    class_weights[key] = sum(value_counts.values()) - value / sum(value_counts.values())

class_weights


class_weights = {0 : 20.37 , 1 : 79.73}

from sklearn.linear_model import LogisticRegression 

model = LogisticRegression(class_weight=class_weights)
model.fit(Xtrain , Ytrain)

predictions = model.predict(Xtest)


def Accuracy(Truths , Predictions):
    return np.mean(Truths == Predictions)



Accuracy(Ytest , predictions)
import seaborn as sns 

matrix = confusion_matrix(Ytest , predictions)
sns.heatmap(matrix , annot=True)


precision(1 , matrix) , recall(1 , matrix)



print(f'Accuracy Score: {accuracy_score(Ytest,predictions)}')
print(f'Confusion Matrix: \n{confusion_matrix(Ytest, predictions)}')
print(f'Area Under Curve: {roc_auc_score(Ytest, predictions)}')
print(f'Recall score: {recall_score(Ytest,predictions)}')




from sklearn.linear_model import LogisticRegression

model = LogisticRegression()
model.fit(Xtrain, Ytrain)

predictions = model.predict(Xtest)
pred_probs = model.predict_proba(Xtest)




pred_probs[:3]

pred_probs = pred_probs[:, 1]


from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, roc_curve, roc_auc_score

matrix = confusion_matrix(Ytest, predictions)
print(matrix)
sns.heatmap(matrix, annot=True)



def Accuracy(Truths, Predictions):
    return np.mean(Truths == Predictions)

print("Validation Accuracy:", Accuracy(Ytest, predictions))


print("Precision:", precision_score(Ytest, predictions))


print("Precision:", recall_score(Ytest, predictions))


Fpr, Tpr, _= roc_curve(Ytest, pred_probs)
plt.plot(Fpr, Tpr, marker='.', label='without class weights')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend()
plt.show()


Auc = roc_auc_score(Ytest, pred_probs)
print("Area Under Curve:", Auc)



import pickle

def save_object(obj , name):
    pickle_obj = open(f"{name}.pck","wb")
    pickle.dump(obj, pickle_obj)
    pickle_obj.close()
# Label encode the Object Datatypes 
from sklearn.preprocessing import LabelEncoder

d_types = dict(data.dtypes)

for name , type_ in d_types.items():
    if str(type_) == 'object':
        Le = LabelEncoder()
        data[name] = Le.fit_transform(data[name])
        save_object(Le , f"Label_Encoder_{name}")

# one hot encode geography 
# optional 

from sklearn.preprocessing import OneHotEncoder

onehotencoder = OneHotEncoder()
encodings = onehotencoder.fit_transform(data['Geography'].values.reshape(-1,1)).toarray()
save_object(onehotencoder , "OneHotEncoder_Geography")

#values = dict(data["Geography"].value_counts())
values = data["Geography"].unique()

for val in values:
    data["Geography_" + str(val)] = encodings[:,val]

data = data.drop(["Geography"] , axis = 1)

data.head()



remaining_columns = list(data.columns)
remaining_columns.remove("Exited")
save_object(remaining_columns , "columns")
# Feature and Target vector
​
X = data[remaining_columns].values 
Y = data['Exited'].values.astype(np.uint8)
from sklearn.model_selection import train_test_split
​
Xtrain , Xtest , Ytrain , Ytest = train_test_split(X , Y , test_size = 0.2 , random_state = 4)
from sklearn.preprocessing import StandardScaler
​
Scaler = StandardScaler()
Xtrain = Scaler.fit_transform(Xtrain)
Xtest = Scaler.transform(Xtest)
​
save_object(Scaler , "Scaler")
# check whether data is standardized or not 
# mean should be 1 
​
plt.ylim(-1,1)
​
means = []
for i in range(X.shape[1]):
    means.append(np.mean(Xtest[:,i]))
plt.plot(means , scaley=False)

# Check variances 

plt.ylim(0,2)

vars = []
for i in range(X.shape[1]):
    vars.append(np.var(Xtest[:,i]))
plt.plot(vars)# finding class weights 

value_counts = dict(data["Exited"].value_counts())
print(value_counts)


class_weights = {0 : 20.37 , 1 : 79.63}


from sklearn.linear_model import LogisticRegression 

model = LogisticRegression(class_weight=class_weights)
model.fit(Xtrain , Ytrain)

predictions = model.predict(Xtest)
save_object(model , "MyModel")
pred_probs = model.predict_proba(Xtest)



# Get the probs of only Churn = "1"

pred_probs = pred_probs[:, 1]


from sklearn.metrics import confusion_matrix,accuracy_score, precision_score,\
                            recall_score,roc_curve,roc_auc_score

matrix = confusion_matrix(Ytest , predictions)
print(matrix)
sns.heatmap(matrix , annot=True)


def Accuracy(Truths , Predictions):
    return np.mean(Truths == Predictions)

print("Validation Accuracy : " , Accuracy(Ytest , predictions))



# Checking precision

print("Precision : " , precision_score(Ytest , predictions))



# Checking recall

print("Precision : " , recall_score(Ytest , predictions))




Fpr, Tpr, _ = roc_curve(Ytest, pred_probs)

plt.plot(Fpr, Tpr, marker='.', label='with class weights')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend()
plt.show()



Auc = roc_auc_score(Ytest, pred_probs)
print(" Area Under Curve : " , Auc)



import pandas as pd 
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pickle



def load_object(name):
    pickle_obj = open(f"{name}.pck","rb")
    obj = pickle.load(pickle_obj)
    return obj


# Load the Data Point 

data = pd.read_csv("Churn_Modelling.csv")

to_be_predicted = data.iloc[10,:].values

col_names = data.columns 
predict_dict = {}

for col_name , val in zip(col_names , to_be_predicted):
    predict_dict[col_name] = val
    
print(predict_dict)



del predict_dict["RowNumber"]
del predict_dict["CustomerId"]
del predict_dict["Surname"]



real_output = predict_dict["Exited"]
del predict_dict["Exited"]



predict_dict["Gender"] = load_object("Label_Encoder_Gender").transform(np.array(predict_dict["Gender"]).reshape(-1,))[0]


predict_dict["Geography"] = load_object("Label_Encoder_Geography").transform(np.array(predict_dict["Geography"]).reshape(-1,))[0]


predict_dict

predict_dict["Geography_ohe"] = load_object("OneHotEncoder_Geography").transform(predict_dict["Geography"].reshape(-1,1)).toarray()[0]

predict_dict

del predict_dict["Geography"]

for e , i in enumerate(predict_dict["Geography_ohe"]):
    predict_dict["Geography_" + str(e)] = i


del predict_dict["Geography_ohe"]


predict_dict

# Lets make the main array 

col_sequence = load_object("columns")
array = []

for col_name in col_sequence :
    array.append(predict_dict[col_name])

array = np.array(array)

print(array)


array = load_object("Scaler").transform(array.reshape(1,-1))


prediction = load_object("MyModel").predict(array)[0]
print(prediction)


print(" Original : " , real_output , " Predicted : " , prediction)


